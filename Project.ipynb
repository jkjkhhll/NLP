{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ac55b2",
   "metadata": {},
   "source": [
    "## 0. Preprocessing\n",
    "\n",
    "Files in the package:\n",
    "\n",
    "- get_corpus_titles.py (Follow links from the page \"Cognitive Science\" to get the page titles)\n",
    "- titles_to_json.py (I first pickled the titles list, but then decided to use json for transparency)\n",
    "- read_wikidump.py (Process wikipedia dump and get nouns for articles in titles file)\n",
    "- wikireader.py (custom ContentHandler implementation for xml.sax)\n",
    "\n",
    "\n",
    "Corpus files and model (compressed sizes: corpus 83 Mb, model 32 Mb):\n",
    "\n",
    "https://drive.google.com/drive/folders/1PFi-n-vCxsyd3YQZ_sBstgGLzM4VGEsL?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547bf809",
   "metadata": {},
   "source": [
    "## 1. Import corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad6ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing corpus\t: 100%|██████████| 59335/59335 [00:06<00:00, 8893.26it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "titles = []\n",
    "corpus_raw = []\n",
    "n_docs = 59335\n",
    "\n",
    "progress = tqdm(total=n_docs)\n",
    "progress.set_description('Importing corpus\\t')\n",
    "\n",
    "corpus_file = os.path.join('corpus_redirects', 'corpus_fulltext.json')\n",
    "\n",
    "with open(corpus_file, 'r') as f:\n",
    "    while True:\n",
    "        jdoc = f.readline()\n",
    "        if not jdoc:\n",
    "            break\n",
    "        \n",
    "        doc = json.loads(jdoc)\n",
    "        titles.append(doc['page'])\n",
    "        corpus_raw.append(doc['text'].split(' '))\n",
    "        progress.update(1)\n",
    "        \n",
    "progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b385cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'precision',\n",
       " 'coordinate',\n",
       " 'time',\n",
       " 'standard',\n",
       " 'passage',\n",
       " 'time',\n",
       " 'geoid',\n",
       " 'realisation',\n",
       " 'offset']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_raw[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eaa5a6",
   "metadata": {},
   "source": [
    "## 2. Count word frequences and keep only words that appear more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d25bb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Count word frequences\t: 100%|██████████| 59335/59335 [00:11<00:00, 5089.28it/s]\n",
      "Remove single words\t: 100%|██████████| 59335/59335 [00:11<00:00, 5386.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'precision',\n",
       " 'coordinate',\n",
       " 'time',\n",
       " 'standard',\n",
       " 'passage',\n",
       " 'time',\n",
       " 'geoid',\n",
       " 'realisation',\n",
       " 'offset']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Count word frequencies\n",
    "progress = tqdm(total=n_docs)\n",
    "progress.set_description('Count word frequences\\t')\n",
    "\n",
    "freq = defaultdict(int)\n",
    "for doc in corpus_raw:\n",
    "    for tok in doc:\n",
    "        freq[tok] += 1\n",
    "    progress.update(1)\n",
    "progress.close()\n",
    "\n",
    "# Only keep words that appear more than once and are 2 or more chars long\n",
    "progress = tqdm(total=n_docs)\n",
    "progress.set_description('Remove single words\\t')\n",
    "\n",
    "corpus = []\n",
    "for doc in corpus_raw:\n",
    "    corpus.append([tok for tok in doc if freq[tok] > 1 and len(tok) > 1])\n",
    "    progress.update(1)\n",
    "progress.close()\n",
    "\n",
    "corpus[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a1bad5",
   "metadata": {},
   "source": [
    "## 3. Build gensim dictionary and BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9de9551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59335/59335 [00:19<00:00, 3089.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# WARNING: SLOW!\n",
    "#dictionary = gensim.corpora.Dictionary(corpus)\n",
    "#dictionary.save(\"dictionary.gensim\")\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary.load(\"dictionary.gensim\")\n",
    "bow = [dictionary.doc2bow(doc) for doc in tqdm(corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6277ddb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 2), (2, 1), (3, 3), (4, 1), (5, 1), (6, 3), (7, 2), (8, 3), (9, 2), (10, 5), (11, 1), (12, 2), (13, 2), (14, 18), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 3), (27, 1), (28, 1), (29, 2), (30, 3), (31, 1), (32, 1), (33, 6), (34, 3), (35, 2), (36, 1), (37, 1), (38, 2), (39, 3), (40, 1), (41, 1), (42, 4), (43, 1), (44, 2), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 3), (51, 1), (52, 1), (53, 1), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 2), (64, 1), (65, 1), (66, 3), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 23), (73, 2), (74, 12), (75, 1), (76, 1), (77, 1), (78, 4), (79, 1), (80, 2), (81, 1), (82, 1), (83, 1), (84, 2), (85, 1), (86, 1), (87, 29), (88, 1), (89, 1), (90, 2), (91, 1), (92, 1), (93, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bdc776",
   "metadata": {},
   "source": [
    "## 4. Train and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95184fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: SLOW!\n",
    "#topic_model = gensim.models.LdaModel(bow, id2word=dictionary, num_topics=30, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81fc7cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.save(\"model.gensim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b1cf71",
   "metadata": {},
   "source": [
    "## 5. Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c3b2684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.028*\"design\" + 0.020*\"system\" + 0.013*\"power\" + 0.012*\"vehicle\" + 0.012*\"control\" + 0.011*\"car\" + 0.010*\"machine\" + 0.009*\"engine\" + 0.007*\"use\" + 0.007*\"technology\"')\n",
      "(1, '0.043*\"animal\" + 0.027*\"specie\" + 0.014*\"human\" + 0.012*\"evolution\" + 0.011*\"bird\" + 0.011*\"fish\" + 0.010*\"population\" + 0.009*\"organism\" + 0.008*\"gene\" + 0.008*\"group\"')\n",
      "(2, '0.025*\"century\" + 0.014*\"year\" + 0.011*\"day\" + 0.010*\"time\" + 0.010*\"period\" + 0.008*\"culture\" + 0.008*\"stone\" + 0.008*\"art\" + 0.008*\"site\" + 0.007*\"god\"')\n",
      "(3, '0.020*\"state\" + 0.019*\"century\" + 0.015*\"country\" + 0.014*\"people\" + 0.014*\"government\" + 0.013*\"power\" + 0.012*\"p.\" + 0.011*\"history\" + 0.011*\"population\" + 0.010*\"war\"')\n",
      "(4, '0.017*\"philosophy\" + 0.013*\"religion\" + 0.011*\"world\" + 0.010*\"life\" + 0.009*\"nature\" + 0.009*\"view\" + 0.009*\"idea\" + 0.008*\"form\" + 0.008*\"philosopher\" + 0.008*\"belief\"')\n",
      "(5, '0.059*\"film\" + 0.020*\"art\" + 0.014*\"series\" + 0.013*\"medium\" + 0.012*\"story\" + 0.012*\"character\" + 0.010*\"television\" + 0.009*\"artist\" + 0.009*\"time\" + 0.008*\"movie\"')\n",
      "(6, '0.035*\"patient\" + 0.032*\"disease\" + 0.029*\"health\" + 0.022*\"treatment\" + 0.017*\"care\" + 0.015*\"risk\" + 0.014*\"drug\" + 0.012*\"case\" + 0.012*\"blood\" + 0.011*\"cancer\"')\n",
      "(7, '0.047*\"party\" + 0.043*\"election\" + 0.040*\"state\" + 0.037*\"member\" + 0.025*\"government\" + 0.023*\"vote\" + 0.018*\"candidate\" + 0.015*\"leader\" + 0.014*\"president\" + 0.013*\"voting\"')\n",
      "(8, '0.017*\"code\" + 0.016*\"bit\" + 0.015*\"language\" + 0.014*\"type\" + 0.013*\"program\" + 0.013*\"programming\" + 0.013*\"system\" + 0.013*\"object\" + 0.012*\"value\" + 0.012*\"datum\"')\n",
      "(9, '0.064*\"woman\" + 0.042*\"law\" + 0.028*\"right\" + 0.019*\"man\" + 0.013*\"case\" + 0.011*\"court\" + 0.010*\"movement\" + 0.010*\"gender\" + 0.009*\"state\" + 0.009*\"sex\"')\n",
      "(10, '0.046*\"cell\" + 0.015*\"protein\" + 0.014*\"gene\" + 0.014*\"neuron\" + 0.012*\"brain\" + 0.011*\"receptor\" + 0.009*\"muscle\" + 0.009*\"system\" + 0.008*\"nerve\" + 0.007*\"function\"')\n",
      "(11, '0.046*\"model\" + 0.035*\"datum\" + 0.025*\"method\" + 0.020*\"analysis\" + 0.016*\"test\" + 0.015*\"probability\" + 0.014*\"process\" + 0.013*\"distribution\" + 0.013*\"value\" + 0.013*\"time\"')\n",
      "(12, '0.062*\"music\" + 0.047*\"song\" + 0.034*\"album\" + 0.021*\"band\" + 0.012*\"number\" + 0.011*\"year\" + 0.011*\"performance\" + 0.010*\"artist\" + 0.010*\"recording\" + 0.010*\"record\"')\n",
      "(13, '0.016*\"image\" + 0.016*\"time\" + 0.016*\"field\" + 0.014*\"signal\" + 0.012*\"quantum\" + 0.012*\"system\" + 0.011*\"frequency\" + 0.011*\"energy\" + 0.010*\"color\" + 0.010*\"light\"')\n",
      "(14, '0.042*\"water\" + 0.023*\"energy\" + 0.014*\"climate\" + 0.012*\"oil\" + 0.011*\"land\" + 0.011*\"change\" + 0.010*\"year\" + 0.010*\"gas\" + 0.010*\"area\" + 0.010*\"plant\"')\n",
      "(15, '0.046*\"child\" + 0.019*\"people\" + 0.017*\"study\" + 0.016*\"age\" + 0.015*\"individual\" + 0.014*\"disorder\" + 0.013*\"behavior\" + 0.013*\"self\" + 0.010*\"person\" + 0.010*\"parent\"')\n",
      "(16, '0.054*\"food\" + 0.026*\"plant\" + 0.018*\"animal\" + 0.015*\"meat\" + 0.012*\"product\" + 0.010*\"diet\" + 0.008*\"fruit\" + 0.008*\"vegan\" + 0.008*\"milk\" + 0.007*\"crop\"')\n",
      "(17, '0.039*\"book\" + 0.036*\"history\" + 0.035*\"work\" + 0.018*\"p.\" + 0.013*\"author\" + 0.012*\"journal\" + 0.011*\"century\" + 0.010*\"year\" + 0.010*\"time\" + 0.010*\"article\"')\n",
      "(18, '0.017*\"theory\" + 0.016*\"system\" + 0.015*\"development\" + 0.014*\"group\" + 0.012*\"society\" + 0.012*\"study\" + 0.011*\"culture\" + 0.011*\"work\" + 0.011*\"process\" + 0.010*\"research\"')\n",
      "(19, '0.170*\"game\" + 0.043*\"player\" + 0.042*\"video\" + 0.024*\"team\" + 0.016*\"console\" + 0.012*\"time\" + 0.010*\"title\" + 0.009*\"sport\" + 0.009*\"pc\" + 0.009*\"developer\"')\n",
      "(20, '0.028*\"memory\" + 0.020*\"information\" + 0.017*\"brain\" + 0.017*\"study\" + 0.015*\"psychology\" + 0.015*\"theory\" + 0.014*\"learning\" + 0.013*\"task\" + 0.013*\"research\" + 0.012*\"object\"')\n",
      "(21, '0.030*\"market\" + 0.018*\"price\" + 0.016*\"economy\" + 0.014*\"rate\" + 0.013*\"tax\" + 0.012*\"bank\" + 0.011*\"business\" + 0.010*\"income\" + 0.010*\"company\" + 0.010*\"production\"')\n",
      "(22, '0.019*\"service\" + 0.015*\"company\" + 0.014*\"government\" + 0.013*\"country\" + 0.012*\"information\" + 0.011*\"organization\" + 0.011*\"year\" + 0.010*\"report\" + 0.010*\"policy\" + 0.010*\"security\"')\n",
      "(23, '0.044*\"city\" + 0.025*\"area\" + 0.024*\"building\" + 0.012*\"home\" + 0.011*\"town\" + 0.009*\"house\" + 0.008*\"station\" + 0.008*\"road\" + 0.008*\"museum\" + 0.008*\"service\"')\n",
      "(24, '0.026*\"material\" + 0.015*\"temperature\" + 0.015*\"process\" + 0.013*\"chemical\" + 0.012*\"metal\" + 0.011*\"reactor\" + 0.010*\"water\" + 0.010*\"conservation\" + 0.009*\"reaction\" + 0.009*\"surface\"')\n",
      "(25, '0.033*\"war\" + 0.025*\"attack\" + 0.024*\"force\" + 0.013*\"weapon\" + 0.013*\"army\" + 0.011*\"troop\" + 0.010*\"soldier\" + 0.009*\"ship\" + 0.009*\"battle\" + 0.009*\"officer\"')\n",
      "(26, '0.053*\"student\" + 0.046*\"school\" + 0.033*\"education\" + 0.030*\"university\" + 0.025*\"year\" + 0.021*\"research\" + 0.017*\"program\" + 0.016*\"degree\" + 0.013*\"college\" + 0.013*\"science\"')\n",
      "(27, '0.105*\"language\" + 0.053*\"word\" + 0.020*\"vowel\" + 0.018*\"speech\" + 0.015*\"example\" + 0.015*\"||\" + 0.015*\"form\" + 0.014*\"speaker\" + 0.013*\"sentence\" + 0.012*\"verb\"')\n",
      "(28, '0.028*\"function\" + 0.022*\"space\" + 0.021*\"point\" + 0.021*\"number\" + 0.020*\"theory\" + 0.019*\"set\" + 0.016*\"equation\" + 0.013*\"vector\" + 0.013*\"matrix\" + 0.013*\"problem\"')\n",
      "(29, '0.026*\"user\" + 0.026*\"system\" + 0.020*\"software\" + 0.018*\"computer\" + 0.014*\"device\" + 0.013*\"application\" + 0.013*\"datum\" + 0.013*\"network\" + 0.011*\"version\" + 0.009*\"web\"')\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "tm = LdaModel.load(\"topic_model.gensim\")\n",
    "\n",
    "for t in tm.show_topics(30):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4d2bbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, 0.55607367), (29, 0.22885469), (27, 0.12050904), (0, 0.05737104), (22, 0.02335535)]\n",
      "\n",
      "Top 3 topics:\n",
      "8: Software development\n",
      "29: Computers\n",
      "27: Language\n",
      "\n",
      "ASCII\n",
      "\n",
      "ascii character standard communication ascii code text computer telecommunication equipment device character encoding scheme character internet name character encoding ascii milestone ascii telegraph code use bit teleprinter code datum service work standard meeting x3.2 subcommittee edition standard revision update telegraph code code sorting alphabetization list feature device teleprinter alphabet encode\n"
     ]
    }
   ],
   "source": [
    "# Find topics for a document in the corpus \n",
    "doc_id = 10 \n",
    "\n",
    "# Print topics \n",
    "doc_topics = tm.get_document_topics(bow[doc_id])\n",
    "doc_topics.sort(key=lambda i: i[1], reverse=True)\n",
    "print(doc_topics)\n",
    "\n",
    "print(\"\\nTop 3 topics:\")\n",
    "for t, _ in doc_topics[:3]:\n",
    "    print(f\"{t}: {topic_map[t]}\") \n",
    "    \n",
    "print()\n",
    "\n",
    "# Print the document title and a text sample \n",
    "print(titles[doc_id] + '\\n')\n",
    "print(' '.join(corpus_raw[doc_id][:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd1e04b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some topic title quesses based on the data above (for demonstration purposes)\n",
    "topic_map = {\n",
    "    0: 'Engineering',\n",
    "    1: 'Ecology, evolution',\n",
    "    2: 'History',\n",
    "    3: 'State, history',\n",
    "    4: 'Philosophy, religion',\n",
    "    5: 'Film, TV',\n",
    "    6: 'Medicine',\n",
    "    7: 'Politics',\n",
    "    8: 'Software development',\n",
    "    9: 'Gender',\n",
    "    10: 'Biology',\n",
    "    11: 'Statistics',\n",
    "    12: 'Music',\n",
    "    13: 'Physics',\n",
    "    14: 'Climate',\n",
    "    15: 'Children, parents?',\n",
    "    16: 'Nutrition',\n",
    "    17: 'Books, articles',\n",
    "    18: 'Research',\n",
    "    19: 'Video games',\n",
    "    20: 'Psychology, brain',\n",
    "    21: 'Economics',\n",
    "    22: 'Organizations?',\n",
    "    23: 'Cities and towns',\n",
    "    24: 'Chemistry',\n",
    "    25: 'War',\n",
    "    26: 'Education',\n",
    "    27: 'Language',\n",
    "    28: 'Mathematics',\n",
    "    29: 'Computers'\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
